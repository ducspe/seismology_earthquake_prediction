{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available device:  cuda\n"
     ]
    }
   ],
   "source": [
    "NUMBER_OF_HIDDEN_UNITS = 64 # try 128, 256\n",
    "LEARNING_RATE = 0.9 # try 0.7, 0.8 \n",
    "num_train_steps = 3 # make it 30 or more\n",
    "batch_size = 1\n",
    "LBFGS_MAX_ITERATIONS = 10 # try 20, 25, 30\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"available device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_minmax = pd.HDFStore(\"../../cloudcontainer/concatenated_experiments.hdf5\", mode='r').select(\"alldata_mean_instead_of_NaN/train/minmax\")\n",
    "df_pressure_train_minmax = df_train_minmax[\"pressure\"]\n",
    "df_ae_train_minmax = df_train_minmax[\"ae\"]\n",
    "\n",
    "df_val_minmax = pd.HDFStore(\"../../cloudcontainer/concatenated_experiments.hdf5\", mode='r').select(\"alldata_mean_instead_of_NaN/val/minmax\")\n",
    "df_pressure_val_minmax = df_val_minmax[\"pressure\"]\n",
    "df_ae_val_minmax = df_val_minmax[\"ae\"]\n",
    "\n",
    "df_test_minmax = pd.HDFStore(\"../../cloudcontainer/concatenated_experiments.hdf5\", mode='r').select(\"alldata_mean_instead_of_NaN/test/minmax\")\n",
    "df_pressure_test_minmax = df_test_minmax[\"pressure\"]\n",
    "df_ae_test_minmax = df_test_minmax[\"ae\"]\n",
    "\n",
    "df_train_minmax = df_train_minmax.drop([\"pressure\"], axis=1)\n",
    "df_val_minmax = df_val_minmax.drop([\"pressure\"], axis=1)\n",
    "df_test_minmax = df_test_minmax.drop([\"pressure\"], axis=1)\n",
    "#df_train_minmax = df_train_minmax.drop([\"ae\"], axis=1)\n",
    "#df_val_minmax = df_val_minmax.drop([\"ae\"], axis=1)\n",
    "#df_test_minmax = df_test_minmax.drop([\"ae\"], axis=1)\n",
    "\n",
    "np_train_minmax = df_train_minmax.to_numpy()\n",
    "np_pressure_train_minmax = df_pressure_train_minmax.to_numpy()\n",
    "np_ae_train_minmax = df_ae_train_minmax.to_numpy()\n",
    "\n",
    "np_val_minmax = df_val_minmax.to_numpy()\n",
    "np_pressure_val_minmax = df_pressure_val_minmax.to_numpy()\n",
    "np_ae_val_minmax = df_ae_val_minmax.to_numpy()\n",
    "\n",
    "np_test_minmax = df_test_minmax.to_numpy()\n",
    "np_pressure_test_minmax = df_pressure_test_minmax.to_numpy()\n",
    "np_ae_test_minmax = df_ae_test_minmax.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features= 49\n",
      "shift_step= 5163\n"
     ]
    }
   ],
   "source": [
    "train_series_len = len(np_pressure_train_minmax)\n",
    "val_series_len = len(np_pressure_val_minmax)\n",
    "test_series_len = len(np_pressure_test_minmax)\n",
    "\n",
    "n_features = np_train_minmax.shape[1]\n",
    "print(\"n_features=\", n_features)\n",
    "\n",
    "train_shift_step = int(train_series_len / batch_size)\n",
    "val_shift_step = int(val_series_len / batch_size)\n",
    "test_shift_step = int(test_series_len / batch_size)\n",
    "\n",
    "shift_step = int(test_series_len / batch_size)\n",
    "print(\"shift_step=\", shift_step)\n",
    "\n",
    "np_train_minmax_shifted = np.empty((batch_size, train_series_len, n_features), np.float32)\n",
    "np_pressure_train_minmax_shifted = np.empty((batch_size, train_series_len), np.float32)\n",
    "np_ae_train_minmax_shifted = np.empty((batch_size, train_series_len), np.float32)\n",
    "\n",
    "np_val_minmax_shifted = np.empty((batch_size, val_series_len, n_features), np.float32)\n",
    "np_pressure_val_minmax_shifted = np.empty((batch_size, val_series_len), np.float32)\n",
    "np_ae_val_minmax_shifted = np.empty((batch_size, val_series_len), np.float32)\n",
    "\n",
    "np_test_minmax_shifted = np.empty((batch_size, test_series_len, n_features), np.float32)\n",
    "np_pressure_test_minmax_shifted = np.empty((batch_size, test_series_len), np.float32)\n",
    "np_ae_test_minmax_shifted = np.empty((batch_size, test_series_len), np.float32)\n",
    "\n",
    "\n",
    "for i in range(batch_size):\n",
    "    rolling_amount = shift_step*i\n",
    "    np_train_minmax_shifted[i] = np.roll(np_train_minmax, rolling_amount)\n",
    "    np_pressure_train_minmax_shifted[i] = np.roll(np_pressure_train_minmax, rolling_amount)\n",
    "    np_ae_train_minmax_shifted[i] = np.roll(np_ae_train_minmax, rolling_amount)\n",
    "\n",
    "for i in range(batch_size):\n",
    "    rolling_amount = shift_step*i\n",
    "    np_val_minmax_shifted[i] = np.roll(np_val_minmax, rolling_amount)\n",
    "    np_pressure_val_minmax_shifted[i] = np.roll(np_pressure_val_minmax, rolling_amount)\n",
    "    np_ae_val_minmax_shifted[i] = np.roll(np_ae_val_minmax, rolling_amount)\n",
    "    \n",
    "for i in range(batch_size):\n",
    "    rolling_amount = shift_step*i\n",
    "    np_test_minmax_shifted[i] = np.roll(np_test_minmax, rolling_amount)\n",
    "    np_pressure_test_minmax_shifted[i] = np.roll(np_pressure_test_minmax, rolling_amount)\n",
    "    np_ae_test_minmax_shifted[i] = np.roll(np_ae_test_minmax, rolling_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfig = plt.figure(figsize=(30,15))\\n\\nax1 = fig.add_subplot(221)\\nplt.plot(np_pressure_train_minmax_shifted[0])\\nplt.title(\"Pressure original unshifted\")\\nplt.ylabel(\\'Pressure\\')\\nplt.xlabel(\\'Time step\\')\\nplt.axvline(x=14400, color=\\'r\\')\\nplt.axvline(x=14400+17515, color=\\'r\\')\\n\\nax2 = fig.add_subplot(222)\\nplt.plot(np_pressure_train_minmax_shifted[10])\\nplt.title(\"Pressure shift 1\")\\nplt.ylabel(\\'Pressure\\')\\nplt.xlabel(\\'Time step\\')\\nplt.axvline(x=14400, color=\\'r\\')\\nplt.axvline(x=14400+17515, color=\\'r\\')\\n\\nax3 = fig.add_subplot(223)\\nplt.plot(np_pressure_train_minmax_shifted[20])\\nplt.title(\"Pressure shift 2\")\\nplt.ylabel(\\'Pressure\\')\\nplt.xlabel(\\'Time step\\')\\nplt.axvline(x=14400, color=\\'r\\')\\nplt.axvline(x=14400+17515, color=\\'r\\')\\n\\nax4 = fig.add_subplot(224)\\nplt.plot(np_pressure_train_minmax_shifted[29])\\nplt.title(\"Pressure shift 3\")\\nplt.ylabel(\\'Pressure\\')\\nplt.xlabel(\\'Time step\\')\\nplt.axvline(x=14400, color=\\'r\\')\\nplt.axvline(x=14400+17515, color=\\'r\\')\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can uncomment the below plotting code only if you have set batch_size to 30 or more.\n",
    "'''\n",
    "fig = plt.figure(figsize=(30,15))\n",
    "\n",
    "ax1 = fig.add_subplot(221)\n",
    "plt.plot(np_pressure_train_minmax_shifted[0])\n",
    "plt.title(\"Pressure original unshifted\")\n",
    "plt.ylabel('Pressure')\n",
    "plt.xlabel('Time step')\n",
    "plt.axvline(x=14400, color='r')\n",
    "plt.axvline(x=14400+17515, color='r')\n",
    "\n",
    "ax2 = fig.add_subplot(222)\n",
    "plt.plot(np_pressure_train_minmax_shifted[10])\n",
    "plt.title(\"Pressure shift 1\")\n",
    "plt.ylabel('Pressure')\n",
    "plt.xlabel('Time step')\n",
    "plt.axvline(x=14400, color='r')\n",
    "plt.axvline(x=14400+17515, color='r')\n",
    "\n",
    "ax3 = fig.add_subplot(223)\n",
    "plt.plot(np_pressure_train_minmax_shifted[20])\n",
    "plt.title(\"Pressure shift 2\")\n",
    "plt.ylabel('Pressure')\n",
    "plt.xlabel('Time step')\n",
    "plt.axvline(x=14400, color='r')\n",
    "plt.axvline(x=14400+17515, color='r')\n",
    "\n",
    "ax4 = fig.add_subplot(224)\n",
    "plt.plot(np_pressure_train_minmax_shifted[29])\n",
    "plt.title(\"Pressure shift 3\")\n",
    "plt.ylabel('Pressure')\n",
    "plt.xlabel('Time step')\n",
    "plt.axvline(x=14400, color='r')\n",
    "plt.axvline(x=14400+17515, color='r')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfig = plt.figure(figsize=(30,15))\\n\\nax1 = fig.add_subplot(221)\\nplt.plot(np_ae_train_minmax_shifted[0])\\nplt.title(\"AE original unshifted\")\\nplt.ylabel(\\'AE\\')\\nplt.xlabel(\\'Time step\\')\\nplt.axvline(x=14400, color=\\'r\\')\\nplt.axvline(x=14400+17515, color=\\'r\\')\\n\\nax2 = fig.add_subplot(222)\\nplt.plot(np_ae_train_minmax_shifted[10])\\nplt.title(\"AE shift 1\")\\nplt.ylabel(\\'AE\\')\\nplt.xlabel(\\'Time step\\')\\nplt.axvline(x=14400, color=\\'r\\')\\nplt.axvline(x=14400+17515, color=\\'r\\')\\n\\nax3 = fig.add_subplot(223)\\nplt.plot(np_ae_train_minmax_shifted[20])\\nplt.title(\"AE shift 2\")\\nplt.ylabel(\\'AE\\')\\nplt.xlabel(\\'Time step\\')\\nplt.axvline(x=14400, color=\\'r\\')\\nplt.axvline(x=14400+17515, color=\\'r\\')\\n\\nax4 = fig.add_subplot(224)\\nplt.plot(np_ae_train_minmax_shifted[29])\\nplt.title(\"AE shift 3\")\\nplt.ylabel(\\'AE\\')\\nplt.xlabel(\\'Time step\\')\\nplt.axvline(x=14400, color=\\'r\\')\\nplt.axvline(x=14400+17515, color=\\'r\\')\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can uncomment the below plotting code only if you have set batch_size to 30 or more.\n",
    "'''\n",
    "fig = plt.figure(figsize=(30,15))\n",
    "\n",
    "ax1 = fig.add_subplot(221)\n",
    "plt.plot(np_ae_train_minmax_shifted[0])\n",
    "plt.title(\"AE original unshifted\")\n",
    "plt.ylabel('AE')\n",
    "plt.xlabel('Time step')\n",
    "plt.axvline(x=14400, color='r')\n",
    "plt.axvline(x=14400+17515, color='r')\n",
    "\n",
    "ax2 = fig.add_subplot(222)\n",
    "plt.plot(np_ae_train_minmax_shifted[10])\n",
    "plt.title(\"AE shift 1\")\n",
    "plt.ylabel('AE')\n",
    "plt.xlabel('Time step')\n",
    "plt.axvline(x=14400, color='r')\n",
    "plt.axvline(x=14400+17515, color='r')\n",
    "\n",
    "ax3 = fig.add_subplot(223)\n",
    "plt.plot(np_ae_train_minmax_shifted[20])\n",
    "plt.title(\"AE shift 2\")\n",
    "plt.ylabel('AE')\n",
    "plt.xlabel('Time step')\n",
    "plt.axvline(x=14400, color='r')\n",
    "plt.axvline(x=14400+17515, color='r')\n",
    "\n",
    "ax4 = fig.add_subplot(224)\n",
    "plt.plot(np_ae_train_minmax_shifted[29])\n",
    "plt.title(\"AE shift 3\")\n",
    "plt.ylabel('AE')\n",
    "plt.xlabel('Time step')\n",
    "plt.axvline(x=14400, color='r')\n",
    "plt.axvline(x=14400+17515, color='r')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 41304, 49)\n",
      "torch.Size([1, 41303, 49])\n",
      "torch.Size([1, 41303])\n"
     ]
    }
   ],
   "source": [
    "train_input_torch = torch.from_numpy(np_train_minmax_shifted[:, :-1,:]).to(device)\n",
    "train_target_torch = torch.from_numpy(np_pressure_train_minmax_shifted[:, 1:]).to(device)\n",
    "\n",
    "val_input_torch = torch.from_numpy(np_val_minmax_shifted[:, :-1,:]).to(device)\n",
    "val_target_torch = torch.from_numpy(np_pressure_val_minmax_shifted[:, 1:]).to(device)\n",
    "\n",
    "test_input_torch = torch.from_numpy(np_test_minmax_shifted[:, :-1,:]).to(device)\n",
    "test_target_torch = torch.from_numpy(np_pressure_test_minmax_shifted[:, 1:]).to(device)\n",
    "\n",
    "print(np_train_minmax_shifted.shape)\n",
    "print(train_input_torch.shape)\n",
    "print(train_target_torch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DKRZSeismologyLSTM(nn.Module):\n",
    "    def __init__(self, num_hidden=NUMBER_OF_HIDDEN_UNITS):\n",
    "        super(DKRZSeismologyLSTM, self).__init__()\n",
    "        self.num_hidden = num_hidden\n",
    "        self.layer1 = nn.LSTMCell(49, self.num_hidden).to(device) # we will feed in one sample at a time, and then zero out the h and c variables after all train data points were seen.\n",
    "        self.layer2 = nn.LSTMCell(self.num_hidden, self.num_hidden).to(device)\n",
    "        self.out = nn.Linear(self.num_hidden, 1).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"input x shape: \", x.size())\n",
    "        num_batches = x.size(0)\n",
    "        print(\"num_batches\", num_batches)\n",
    "        output_list = []\n",
    "        \n",
    "        h_t1 = torch.zeros(num_batches, self.num_hidden, dtype=torch.float32).to(device)\n",
    "        c_t1 = torch.zeros(num_batches, self.num_hidden, dtype=torch.float32).to(device)\n",
    "        h_t2 = torch.zeros(num_batches, self.num_hidden, dtype=torch.float32).to(device)\n",
    "        c_t2 = torch.zeros(num_batches, self.num_hidden, dtype=torch.float32).to(device)\n",
    "\n",
    "        for input_split in x.split(1, dim=1):\n",
    "            #print(\"input_split before:\", input_split.size())\n",
    "            input_split_reshaped = input_split.reshape(num_batches, 49)\n",
    "            #print(\"input_split after:\", input_split_reshaped.size())\n",
    "            h_t1, c_t1 = self.layer1(input_split_reshaped, (h_t1, c_t1))\n",
    "            h_t2, c_t2 = self.layer2(h_t1, (h_t2, c_t2))\n",
    "            output = self.out(h_t2)\n",
    "            output_list.append(output)\n",
    "\n",
    "        outputs = torch.cat(output_list, dim=1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seismology_model = DKRZSeismologyLSTM().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.LBFGS(seismology_model.parameters(), lr=LEARNING_RATE, max_iter=LBFGS_MAX_ITERATIONS)\n",
    "\n",
    "def optimization_func():\n",
    "    optimizer.zero_grad()\n",
    "    model_output = seismology_model(train_input_torch) # notice that this allows us to add the entire data\n",
    "    loss = criterion(model_output, train_target_torch)\n",
    "    print(\"loss=\", loss)\n",
    "    loss.backward()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step  1\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.3102, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.2799, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.0437, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.0434, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.0432, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.0419, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.0433, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.0343, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "intermediary_train_loss:  0.03356194496154785\n",
      "input x shape:  torch.Size([1, 5162, 49])\n",
      "num_batches 1\n",
      "intermediary_val_loss:  0.035283904522657394\n",
      "Step  2\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.0336, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.0322, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(127.7775, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(1.0195, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.1430, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(11.8430, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(5.0101, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(8.4783, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(2.3685, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "intermediary_train_loss:  0.7617514729499817\n",
      "input x shape:  torch.Size([1, 5162, 49])\n",
      "num_batches 1\n",
      "intermediary_val_loss:  0.9835413694381714\n",
      "Step  3\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.7618, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.1602, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.1312, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.0883, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.0714, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.0489, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.0336, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.0294, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "loss= tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "input x shape:  torch.Size([1, 41303, 49])\n",
      "num_batches 1\n",
      "intermediary_train_loss:  0.022813815623521805\n",
      "input x shape:  torch.Size([1, 5162, 49])\n",
      "num_batches 1\n",
      "intermediary_val_loss:  0.05247844383120537\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for step in range(num_train_steps):\n",
    "    print(\"Step \", step + 1)\n",
    "    optimizer.step(optimization_func)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        interemdiary_train_pred = seismology_model(train_input_torch)\n",
    "        intermediary_train_loss = criterion(interemdiary_train_pred, train_target_torch)\n",
    "        print(\"intermediary_train_loss: \", intermediary_train_loss.item())\n",
    "        np_pred_cpu_train = interemdiary_train_pred.detach().cpu().numpy()[0] # index 0 here means basically the original unshifted dataset\n",
    "        target_cpu_train = train_target_torch.detach().cpu().numpy()[0] # index 0 here means basically the original unshifted dataset\n",
    "    \n",
    "        intermediary_val_pred = seismology_model(val_input_torch)\n",
    "        intermediary_val_loss = criterion(intermediary_val_pred, val_target_torch)\n",
    "        print(\"intermediary_val_loss: \", intermediary_val_loss.item())\n",
    "        np_pred_cpu_val = intermediary_val_pred.detach().cpu().numpy()[0] # index 0 here means basically the original unshifted dataset\n",
    "        target_cpu_val = val_target_torch.detach().cpu().numpy()[0] # index 0 here means basically the original unshifted dataset\n",
    "        \n",
    "        # Create figure:\n",
    "        fig, ax = plt.subplots(figsize=(16, 10))\n",
    "        x_data = range(len(np_pred_cpu_train)+len(np_pred_cpu_val))\n",
    "        ax.plot(x_data[:len(np_pred_cpu_train)], np_pred_cpu_train, color=\"blue\", label=\"Train prediction\")\n",
    "        ax.plot(x_data[:len(np_pred_cpu_train)], target_cpu_train, color=\"orange\", label=\"Train ground truth\")\n",
    "        ax.plot(x_data[len(np_pred_cpu_train):len(np_pred_cpu_train)+len(np_pred_cpu_val)], np_pred_cpu_val, color=\"black\", label=\"Validation prediction\")\n",
    "        ax.plot(x_data[len(np_pred_cpu_train):len(np_pred_cpu_train)+len(np_pred_cpu_val)], target_cpu_val, color=\"red\", label=\"Validation ground truth\")\n",
    "        ax.set_title(f\"Train Epoch {step}\", fontsize=20)\n",
    "        ax.set_xlabel(\"Time Index\", fontsize=16)\n",
    "        ax.set_ylabel(\"Pressure\", fontsize=16)\n",
    "        ax.legend()\n",
    "        props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "        text_box_str = f\"val error={intermediary_val_loss.item()}\" + f\"\\ntrain error={intermediary_train_loss.item()}\"\n",
    "        ax.text(0.35, 0.98, text_box_str, transform=ax.transAxes, fontsize=14, verticalalignment='top', bbox=props)\n",
    "        \n",
    "        # Save figure:\n",
    "        fig.savefig(f\"../../cloudcontainer/experiments_related/LSTM_train_saved_material/afterstep_{step}\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Save model:\n",
    "        torch.save(seismology_model, f\"../../cloudcontainer/experiments_related/LSTM_train_saved_material/trained_seismology_model_afterstep_{step}.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniversalK",
   "language": "python",
   "name": "unik"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aed4deef961856cbd687edbc83886a682e67270f8fb867468c4920bcd3898d8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
